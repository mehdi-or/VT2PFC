{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sR5xtc3vZpXx"
      ],
      "authorship_tag": "ABX9TyNG/2RNLb4je4THOWDy7478",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-or/VT2PFC/blob/main/Alternating_DATRACE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XQaaLOZCZaAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656488a4-6014-4d02-c5a5-8d2e9ce125a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for setting seed for reproducility"
      ],
      "metadata": {
        "id": "34eaW-icZk8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "    random.seed(seed_value)  # Python random module\n",
        "    np.random.seed(seed_value)  # Numpy module\n",
        "    torch.manual_seed(seed_value)  # PyTorch random number generator for CPU\n",
        "\n",
        "    # If you are using CUDA\n",
        "    torch.cuda.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
        "\n",
        "    # Additional configurations to enhance reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "ibjoKU_9ZmEz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Implimentation of DATRACE (VT2PF)"
      ],
      "metadata": {
        "id": "sR5xtc3vZpXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DATRACE(nn.Module):\n",
        "    def __init__(self, input_size_VT, input_size_PF, hidden_size, bottleneck_size, num_classes):\n",
        "        super(DATRACE, self).__init__()\n",
        "        # Encoder\n",
        "        self.VT_in = nn.Linear(input_size_VT, hidden_size)\n",
        "        self.PF_in = nn.Linear(input_size_PF, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, bottleneck_size)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(bottleneck_size, hidden_size)\n",
        "        self.PF_out = nn.Linear(hidden_size, input_size_PF)\n",
        "        self.VT_out = nn.Linear(hidden_size, input_size_VT)\n",
        "\n",
        "        # Classifier connected to the bottleneck\n",
        "        self.classifier = nn.Linear(bottleneck_size, num_classes)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # Encoder 1\n",
        "        x1 = torch.tanh(self.VT_in(x1))\n",
        "        x1 = self.dropout(x1)\n",
        "        encoded = torch.tanh(self.fc2(x1))\n",
        "\n",
        "        #Encoder 2\n",
        "        x2 = torch.tanh(self.VT_in(x2))\n",
        "        x2 = self.dropout(x2)\n",
        "        encoded = torch.tanh(self.fc2(x2)) # here the \"encoded\" is simply just overwritten by \"fc2(x2)\". This is a problem that requires to concatenate the ouput of fc2(x1) and fc2(x2)\n",
        "\n",
        "        # Decoder 1\n",
        "        x1 = torch.tanh(self.fc3(encoded))\n",
        "        decoded_PF = self.PF_out(x1)\n",
        "\n",
        "        # Decoder 2\n",
        "        x2 = torch.tanh(self.fc3(encoded))\n",
        "        decoded_VT = self.VT_out(x2)\n",
        "\n",
        "        # Classifier\n",
        "        logits = self.classifier(encoded)\n",
        "        #probabilities = F.softmax(logits, dim=1)\n",
        "        probabilities = logits\n",
        "\n",
        "        return decoded_PF, decoded_VT, probabilities\n",
        "\n",
        "\n",
        "# Example model instantiation\n",
        "input_size_VT = 1500 # e.g., for MNIST\n",
        "input_size_PF = 1000\n",
        "hidden_size = 128\n",
        "bottleneck_size = 32\n",
        "num_classes = 10 # e.g., for MNIST classification\n",
        "\n",
        "model = DATRACE(input_size_VT=input_size_VT, input_size_PF=input_size_PF, hidden_size=hidden_size,\n",
        "                                  bottleneck_size=bottleneck_size, num_classes=num_classes)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "sJWeg7UsZpFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing and preprocessing the data"
      ],
      "metadata": {
        "id": "AuBoZXmmNKNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_VTC(subject):\n",
        "    with h5py.File(r'/content/gdrive/MyDrive/Colab Notebooks/CNC data/hrfAll_VT_PETERS.hdf5', 'r') as hdf:\n",
        "        data0 = hdf.get('items/'+str(subject)+'/rcargs/items/0')\n",
        "        data_vtc = np.array(data0)\n",
        "        data_vtc = np.delete(data_vtc,np.where(~data_vtc.any(axis=0))[0],axis=1)\n",
        "    return(data_vtc)\n",
        "\n",
        "def load_data_PFC(subject):\n",
        "    with h5py.File(r'/content/gdrive/MyDrive/Colab Notebooks/CNC data/hrfAll_DLPFC_PETERS.hdf5', 'r') as hdf:\n",
        "        data0_pfc = hdf.get('items/'+str(subject)+'/rcargs/items/0')\n",
        "        data_pfc = np.array(data0_pfc)\n",
        "        data_pfc = np.delete(data_pfc,np.where(~data_pfc.any(axis=0))[0],axis=1)\n",
        "    return(data_pfc)\n",
        "\n",
        "def preprocessign (data, labels2categ, shuffle_index):\n",
        "  data_train, data_test, y_categ_train, y_categ_test, map_train_index, map_test_index = train_test_split(data, labels2categ, shuffle_index, random_state=42)\n",
        "  #scaler = StandardScaler()\n",
        "  scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "  X_train = scaler.fit_transform(data_train)\n",
        "  X_test = scaler.transform(data_test)\n",
        "  return X_train, X_test, y_categ_train, y_categ_test, map_train_index, map_test_index\n",
        "\n",
        "#setting the labels for pytorch is differen from keras\n",
        "# the way it works is that we need to assign a number to each categorical class\n",
        "unique_labels = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/CNC data/unique_aranged.csv', header=None).values[:,1]\n",
        "labels = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/CNC data/label.csv')['y'].values\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)} #mapping form label to its numeric value\n",
        "index_to_label = {idx: label for label, idx in label_to_index.items()} #mapping from numeric label to the name of the label\n",
        "\n",
        "#turning label file into its numeric values\n",
        "numeric_labels = []\n",
        "for label in labels:\n",
        "  numeric_labels.append(label_to_index[label])\n",
        "\n",
        "numeric_labels = np.array(numeric_labels)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#converting all the numpy array inot pytorch tensor\n",
        "\n",
        "VTC = load_data_VTC(37)\n",
        "PFC = load_data_PFC(37)\n",
        "shuffle_index = np.arange(0,3600)\n",
        "VTC_train, VTC_test, y_train, y_test, map_train_index, map_test_index = preprocessign(VTC, numeric_labels, shuffle_index)\n",
        "PFC_train, PFC_test, _, _, _, _ = preprocessign(PFC, numeric_labels, shuffle_index)\n",
        "\n",
        "VTC_tensor_train = torch.tensor(VTC_train, dtype=torch.float32).to(device)\n",
        "VTC_tensor_test = torch.tensor(VTC_test, dtype=torch.float32).to(device)\n",
        "\n",
        "PFC_tensor_train = torch.tensor(PFC_train, dtype=torch.float32).to(device)\n",
        "PFC_tensor_test = torch.tensor(PFC_test, dtype=torch.float32).to(device)\n",
        "\n",
        "y_tensor_train = torch.tensor(y_train)\n",
        "y_tensor_test =torch.tensor(y_test)\n",
        "\n",
        "VTC_train_dataset = TensorDataset(VTC_tensor_train, y_tensor_train)\n",
        "VTC_test_dataset = TensorDataset(VTC_tensor_test, y_tensor_test)\n",
        "\n",
        "PFC_train_dataset = TensorDataset(PFC_tensor_train, y_tensor_train)\n",
        "PFC_test_dataset = TensorDataset(PFC_tensor_test, y_tensor_test)\n",
        "\n",
        "set_seed(42)\n",
        "VTC_train_loader = DataLoader(VTC_train_dataset, batch_size=64, shuffle=True)\n",
        "VTC_test_loader = DataLoader(VTC_train_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "PFC_train_loader = DataLoader(PFC_train_dataset, batch_size=64, shuffle=True)\n",
        "PFC_test_loader = DataLoader(PFC_train_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "train_dataset = TensorDataset(VTC_tensor_train, PFC_tensor_train, y_tensor_train)\n",
        "test_dataset = TensorDataset(VTC_tensor_test, PFC_tensor_test, y_tensor_test)\n",
        "set_seed(42)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "# 2. Define the model, optimizer, and loss functions\n",
        "input_size_VT = VTC_train.shape[1]\n",
        "input_size_PF = PFC_train.shape[1]\n",
        "hidden_size = 500\n",
        "bottleneck_size = 50\n",
        "num_classes = len(unique_labels)"
      ],
      "metadata": {
        "id": "RGzgqLqzNK5O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT implementation of alternating architecture"
      ],
      "metadata": {
        "id": "yVnogIY3ZtbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DATRACE(nn.Module):\n",
        "    def __init__(self, input_dim_VT, input_dim_PF, hidden_dim, bottleneck_dim, num_classes, VT_update =True):\n",
        "        super(DATRACE, self).__init__()\n",
        "        # Encoding layers for the VTC\n",
        "        self.encoder_a = nn.Linear(input_dim_VT, hidden_dim)\n",
        "        # Encoding layers for PFC\n",
        "        self.encoder_b = nn.Linear(input_dim_PF, hidden_dim)\n",
        "\n",
        "        # Shared bottleneck layer\n",
        "        self.shared_bottleneck = nn.Linear(hidden_dim, bottleneck_dim)  # Assume same dim for simplicity\n",
        "\n",
        "        # Decoding layers for PFC\n",
        "        self.decoder_a = nn.Linear(bottleneck_dim, hidden_dim)\n",
        "        self.prediction_PF = nn.Linear(hidden_dim, input_dim_PF)\n",
        "\n",
        "        # Decoding layers for VTC\n",
        "        self.decoder_b = nn.Linear(bottleneck_dim, hidden_dim)\n",
        "        self.prediction_VT = nn.Linear(hidden_dim, input_dim_VT)\n",
        "\n",
        "        # Classification layer attached to the shared bottleneck\n",
        "        self.classifier = nn.Linear(bottleneck_dim, num_classes)\n",
        "    '''\n",
        "    def forward_VT2PF(self, x_a):\n",
        "        encoded_a = torch.tanh(self.encoder_a(x_a))\n",
        "        bottleneck = torch.tanh(self.shared_bottleneck(encoded_a))\n",
        "        decoded_a = torch.tanh(self.decoder_a(bottleneck))\n",
        "        predicted_PF = self.prediction_PF(decoded_a)\n",
        "        class_logits = self.classifier(bottleneck)\n",
        "        return predicted_PF, class_logits\n",
        "\n",
        "    def forward_PF2VT(self, x_b):\n",
        "        encoded_b = torch.tanh(self.encoder_b(x_b))\n",
        "        bottleneck = torch.tanh(self.shared_bottleneck(encoded_b))\n",
        "        decoded_b = torch.tanh(self.decoder_b(bottleneck))\n",
        "        predicted_VT = self.prediction_VT(decoded_b)\n",
        "        class_logits = self.classifier(bottleneck)\n",
        "        return predicted_VT, class_logits\n",
        "    '''\n",
        "\n",
        "    def forward(self, x_a, x_b, VT_update=True):\n",
        "        encoded_a = torch.tanh(self.encoder_a(x_a))\n",
        "        encoded_b = torch.tanh(self.encoder_b(x_b))\n",
        "        if VT_update:\n",
        "          bottleneck = torch.tanh(self.shared_bottleneck(encoded_a))\n",
        "        else:\n",
        "          bottleneck = torch.tanh(self.shared_bottleneck(encoded_b))\n",
        "        decoded_a = torch.tanh(self.decoder_a(bottleneck))\n",
        "        decoded_b = torch.tanh(self.decoder_b(bottleneck))\n",
        "        predicted_PF = self.prediction_PF(decoded_a)\n",
        "        predicted_VT = self.prediction_VT(decoded_b)\n",
        "        class_logits = self.classifier(bottleneck)\n",
        "        return predicted_PF, predicted_VT, class_logits\n",
        "\n",
        "'''\n",
        "# Example usage\n",
        "input_dim_a = 784  # Example dimensions for different inputs\n",
        "input_dim_b = 512\n",
        "hidden_dim = 128  # Set equal for simplicity\n",
        "bottleneck_dim = 32\n",
        "num_classes = 10  # For multi-class classification\n",
        "\n",
        "model = DATRACE(input_dim_a, input_dim_b, hidden_dim, bottleneck_dim, num_classes)\n",
        "\n",
        "# Example inputs\n",
        "x_a = torch.randn(10, input_dim_a)  # Batch of inputs for autoencoder A\n",
        "x_b = torch.randn(10, input_dim_b)  # Batch of inputs for autoencoder B\n",
        "\n",
        "# Forward passes\n",
        "reconstructed_a, class_logits_a = model.forward_VT2PF(x_a)\n",
        "reconstructed_b, class_logits_b = model.forward_PF2VT(x_b)\n",
        "\n",
        "print(f\"Reconstruction A Shape: {reconstructed_a.shape}, Classification Logits A Shape: {class_logits_a.shape}\")\n",
        "print(f\"Reconstruction B Shape: {reconstructed_b.shape}, Classification Logits B Shape: {class_logits_b.shape}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "0nvmf6ZRZt6H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "c9a2d3ed-a5cb-4a6a-f748-e84ac748be5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example usage\\ninput_dim_a = 784  # Example dimensions for different inputs\\ninput_dim_b = 512\\nhidden_dim = 128  # Set equal for simplicity\\nbottleneck_dim = 32\\nnum_classes = 10  # For multi-class classification\\n\\nmodel = DATRACE(input_dim_a, input_dim_b, hidden_dim, bottleneck_dim, num_classes)\\n\\n# Example inputs\\nx_a = torch.randn(10, input_dim_a)  # Batch of inputs for autoencoder A\\nx_b = torch.randn(10, input_dim_b)  # Batch of inputs for autoencoder B\\n\\n# Forward passes\\nreconstructed_a, class_logits_a = model.forward_VT2PF(x_a)\\nreconstructed_b, class_logits_b = model.forward_PF2VT(x_b)\\n\\nprint(f\"Reconstruction A Shape: {reconstructed_a.shape}, Classification Logits A Shape: {class_logits_a.shape}\")\\nprint(f\"Reconstruction B Shape: {reconstructed_b.shape}, Classification Logits B Shape: {class_logits_b.shape}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT alternating Training"
      ],
      "metadata": {
        "id": "07s4t25WZ4Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume DataLoader for autoencoder A and B are defined as data_loader_a and data_loader_b\n",
        "\n",
        "# Model, Loss Functions, and Optimizer\n",
        "model = DATRACE(input_size_VT, input_size_PF, hidden_size, bottleneck_size, num_classes)\n",
        "mse_loss_fn = nn.MSELoss()\n",
        "cross_entropy_loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Example DataLoaders (Replace with your actual DataLoader)\n",
        "#data_loader_a = DataLoader(...)\n",
        "#data_loader_b = DataLoader(...)\n",
        "\n",
        "def train_autoencoder(autoencoder, data_loader, update_VT=True, update_classifier=False):\n",
        "    \"\"\"\n",
        "    Trains either autoencoder A or B, based on the function passed in `autoencoder`.\n",
        "    If `update_classifier` is True, also updates the classifier.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for input_VTC, input_PFC, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predicted_PFC, predicted_VTC, class_logits = autoencoder(input_VTC, input_PFC, update_VT)\n",
        "\n",
        "        # Calculate losses\n",
        "        predicted_loss_PFC = mse_loss_fn(predicted_PFC, input_PFC)\n",
        "        predicted_loss_VTC = mse_loss_fn(predicted_VTC, input_VTC)\n",
        "        classification_loss = cross_entropy_loss_fn(class_logits, labels)\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = predicted_loss_PFC + predicted_loss_VTC\n",
        "        if update_classifier:\n",
        "            total_loss += classification_loss\n",
        "\n",
        "        # Backpropagation and optimizer step\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 5  # Example setting\n",
        "for epoch in range(num_epochs):\n",
        "    # Alternate training between autoencoders and classifier\n",
        "    if epoch % 2 == 0:\n",
        "        update_VT=True\n",
        "        # Freeze parameters for autoencoder B\n",
        "        for param in model.encoder_b.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in model.decoder_b.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze and train autoencoder A\n",
        "        for param in model.encoder_a.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.decoder_a.parameters():\n",
        "            param.requires_grad = True\n",
        "        train_autoencoder(model.forward, VTC_train_loader, update_VT, update_classifier=True)\n",
        "    else:\n",
        "        update_VT=False\n",
        "        # Freeze parameters for autoencoder A\n",
        "        for param in model.encoder_a.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in model.decoder_a.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze and train autoencoder B\n",
        "        for param in model.encoder_b.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.decoder_b.parameters():\n",
        "            param.requires_grad = True\n",
        "        train_autoencoder(model.forward, PFC_train_loader, update_VT, update_classifier=True)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n"
      ],
      "metadata": {
        "id": "nBJwrz_VZ6Cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74460c3d-b1c2-4525-873a-39c5f8121993"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 completed.\n",
            "Epoch 2/5 completed.\n",
            "Epoch 3/5 completed.\n",
            "Epoch 4/5 completed.\n",
            "Epoch 5/5 completed.\n"
          ]
        }
      ]
    }
  ]
}