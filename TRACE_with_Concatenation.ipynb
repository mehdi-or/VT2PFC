{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOCBLKSwUPzixaKJkZ6qVrN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-or/VT2PFC/blob/main/TRACE_with_Concatenation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9kGg0oarABV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##setting random seed for reproducibility"
      ],
      "metadata": {
        "id": "rNF-U-MRsTtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "    random.seed(seed_value)  # Python random module\n",
        "    np.random.seed(seed_value)  # Numpy module\n",
        "    torch.manual_seed(seed_value)  # PyTorch random number generator for CPU\n",
        "\n",
        "    # If you are using CUDA\n",
        "    torch.cuda.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n",
        "\n",
        "    # Additional configurations to enhance reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "dUAMopgYrLIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Architecture of the model"
      ],
      "metadata": {
        "id": "Fhq_6WWhsYIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DATRACE(nn.Module):\n",
        "    def __init__(self, input_size_VT, input_size_PF, hidden_size, bottleneck_size, num_classes):\n",
        "        super(DATRACE, self).__init__()\n",
        "        # Encoder\n",
        "        self.VT_in = nn.Linear(input_size_VT, hidden_size)\n",
        "        self.PF_in = nn.Linear(input_size_PF, hidden_size)\n",
        "        self.concat = nn.Linear(2*hidden_size, hidden_size)\n",
        "        self.fc_BN = nn.Linear(hidden_size, bottleneck_size)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc = nn.Linear(bottleneck_size, hidden_size)\n",
        "        self.PF_out = nn.Linear(hidden_size, input_size_PF)\n",
        "        self.VT_out = nn.Linear(hidden_size, input_size_VT)\n",
        "\n",
        "        # Classifier connected to the bottleneck\n",
        "        self.classifier = nn.Linear(bottleneck_size, num_classes)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward (self, x1, x2):\n",
        "        # Encoder\n",
        "        encoded_VT = torch.tanh(self.VT_in(x1))\n",
        "        encoded_VT = self.dropout(encoded_VT)\n",
        "\n",
        "        encoded_PF = torch.tanh(self.PF_in(x2))\n",
        "        encoded_PF = self.dropout(encoded_PF)\n",
        "\n",
        "        concatenated = torch.cat((encoded_VT, encoded_PF), dim=1)\n",
        "        encoded_concat = torch.tanh(self.concat(concatenated))\n",
        "        BN = torch.tanh(self.fc_BN(encoded_concat))\n",
        "\n",
        "        # Decoder\n",
        "        x3 = torch.tanh(self.fc(BN))\n",
        "        decoded_PF = self.PF_out(x3)\n",
        "\n",
        "        x4 = torch.tanh(self.fc(BN))\n",
        "        decoded_VT = self.VT_out(x4)\n",
        "\n",
        "        # Classifier\n",
        "        logits = self.classifier(BN) # logsoft is automatically applied behinde the scence\n",
        "\n",
        "        return decoded_PF, decoded_VT, logits\n",
        "\n",
        "\n",
        "# Example model instantiation\n",
        "input_size_VT = 1500 # e.g., for MNIST\n",
        "input_size_PF = 1000\n",
        "hidden_size = 128\n",
        "bottleneck_size = 32\n",
        "num_classes = 10 # e.g., for MNIST classification\n",
        "\n",
        "model = DATRACE(input_size_VT=input_size_VT, input_size_PF=input_size_PF, hidden_size=hidden_size,\n",
        "                                  bottleneck_size=bottleneck_size, num_classes=num_classes)\n",
        "#testing wheather the model work as it  should\n",
        "x1=torch.rand(2,input_size_VT)\n",
        "x2=torch.rand(2,input_size_PF)\n",
        "print(model.forward(x1,x2))\n"
      ],
      "metadata": {
        "id": "aB-gd3a5rSQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing the actual VTC and PFC data and feeding them to dataloader"
      ],
      "metadata": {
        "id": "MzC4SkA3rtiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_VTC(subject):\n",
        "    with h5py.File(r'/content/gdrive/MyDrive/Colab Notebooks/CNC data/hrfAll_VT_PETERS.hdf5', 'r') as hdf:\n",
        "        data0 = hdf.get('items/'+str(subject)+'/rcargs/items/0')\n",
        "        data_vtc = np.array(data0)\n",
        "        data_vtc = np.delete(data_vtc,np.where(~data_vtc.any(axis=0))[0],axis=1)\n",
        "    return(data_vtc)\n",
        "\n",
        "def load_data_PFC(subject):\n",
        "    with h5py.File(r'/content/gdrive/MyDrive/Colab Notebooks/CNC data/hrfAll_DLPFC_PETERS.hdf5', 'r') as hdf:\n",
        "        data0_pfc = hdf.get('items/'+str(subject)+'/rcargs/items/0')\n",
        "        data_pfc = np.array(data0_pfc)\n",
        "        data_pfc = np.delete(data_pfc,np.where(~data_pfc.any(axis=0))[0],axis=1)\n",
        "    return(data_pfc)\n",
        "\n",
        "def preprocessign (data, labels2categ, shuffle_index):\n",
        "  data_train, data_test, y_categ_train, y_categ_test, map_train_index, map_test_index = train_test_split(data, labels2categ, shuffle_index, random_state=42)\n",
        "  #scaler = StandardScaler()\n",
        "  scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "  X_train = scaler.fit_transform(data_train)\n",
        "  X_test = scaler.transform(data_test)\n",
        "  return X_train, X_test, y_categ_train, y_categ_test, map_train_index, map_test_index\n",
        "\n",
        "#setting the labels for pytorch is differen from keras\n",
        "# the way it works is that we need to assign a number to each categorical class\n",
        "unique_labels = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/CNC data/unique_aranged.csv', header=None).values[:,1]\n",
        "labels = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/CNC data/label.csv')['y'].values\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)} #mapping form label to its numeric value\n",
        "index_to_label = {idx: label for label, idx in label_to_index.items()} #mapping from numeric label to the name of the label\n",
        "\n",
        "#turning label file into its numeric values\n",
        "numeric_labes = []\n",
        "for label in labels:\n",
        "  numeric_labes.append(label_to_index[label])\n",
        "\n",
        "numeric_labes = np.array(numeric_labes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#converting all the numpy array inot pytorch tensor\n",
        "\n",
        "VTC = load_data_VTC(37)\n",
        "PFC = load_data_PFC(37)\n",
        "shuffle_index = np.arange(0,3600)\n",
        "VTC_train, VTC_test, y_train, y_test, map_train_index, map_test_index = preprocessign(VTC, numeric_labes, shuffle_index)\n",
        "PFC_train, PFC_test, _, _, _, _ = preprocessign(PFC, numeric_labes, shuffle_index)\n",
        "\n",
        "VTC_tensor_train = torch.tensor(VTC_train, dtype=torch.float32).to(device)\n",
        "VTC_tensor_test = torch.tensor(VTC_test, dtype=torch.float32).to(device)\n",
        "\n",
        "PFC_tensor_train = torch.tensor(PFC_train, dtype=torch.float32).to(device)\n",
        "PFC_tensor_test = torch.tensor(PFC_test, dtype=torch.float32).to(device)\n",
        "\n",
        "y_tensor_train = torch.tensor(y_train)\n",
        "y_tensor_test =torch.tensor(y_test)\n",
        "\n",
        "train_dataset = TensorDataset(VTC_tensor_train, PFC_tensor_train, y_tensor_train)\n",
        "test_dataset = TensorDataset(VTC_tensor_test, PFC_tensor_test, y_tensor_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "VV_uBUFZruMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the network"
      ],
      "metadata": {
        "id": "-9Obm-ymsyyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
        "# 2. Define the model, optimizer, and loss functions\n",
        "input_size_VT = VTC_train.shape[1]\n",
        "input_size_PF = PFC_train.shape[1]\n",
        "hidden_size = 500\n",
        "bottleneck_size = 50\n",
        "num_classes = len(unique_labels)\n",
        "model = DATRACE(input_size_VT, input_size_PF, hidden_size, bottleneck_size, num_classes)\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
        "reconstruction_loss_fn = nn.MSELoss()\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Track loss evolution\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "class_loss_history = []\n",
        "\n",
        "alpha = 0.5 # Classifier weigth of the network\n",
        "\n",
        "# 3. Training loop\n",
        "num_epochs = 150\n",
        "for epoch in range(num_epochs):\n",
        "    set_seed(42 + epoch)\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for VTC, PFC, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predicted_PFC, predicted_VTC, probabilities = model.forward(VTC, PFC)\n",
        "        PFC_loss = reconstruction_loss_fn(predicted_PFC, PFC)\n",
        "        VTC_loss = reconstruction_loss_fn(predicted_VTC, VTC)\n",
        "        classification_loss = classification_loss_fn(probabilities, labels)\n",
        "        loss = PFC_loss + VTC_loss + alpha*classification_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_loss_history.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    class_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for VTC, PFC, labels in test_loader:\n",
        "            predicted_PFC, predicted_VTC, probabilities = model(VTC, PFC)\n",
        "            PFC_loss = reconstruction_loss_fn(predicted_PFC, PFC)\n",
        "            VTC_loss = reconstruction_loss_fn(predicted_VTC, VTC)\n",
        "            classification_loss = classification_loss_fn(probabilities, labels)\n",
        "            loss = PFC_loss + VTC_loss + alpha*classification_loss\n",
        "            val_loss += loss.item()\n",
        "            class_loss+=classification_loss.item()\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    val_loss_history.append(val_loss)\n",
        "\n",
        "    class_loss /= len(test_loader)\n",
        "    class_loss_history.append(class_loss)\n",
        "    if (epoch+1)%(num_epochs/10)==0:\n",
        "      print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# 4. Plotting the loss evolution\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_history, label='Training Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.plot(class_loss_history, label='class_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss Evolution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4Jh8xfQvrVh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch a batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "VTC, PFC, labels = next(dataiter)\n",
        "\n",
        "# Reconstruct images through the network\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted_PFC, predicted_VTC, _ = model(VTC, PFC)\n"
      ],
      "metadata": {
        "id": "Xf_CTKUKuHx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fucntions for reconstrution fidelity and reconstruction accuray"
      ],
      "metadata": {
        "id": "SKADKMkzu7Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recons_fid (X, pred):\n",
        "  corr = np.corrcoef(X, pred)\n",
        "  corr = corr[:len(corr)//2, len(corr)//2:]\n",
        "  corr_diag = np.diag(corr)\n",
        "  return np.mean(corr_diag)\n",
        "\n",
        "VTC_fidelity = recons_fid (VTC, predicted_VTC)\n",
        "print(f'VTC reconstruction fidelity is: {VTC_fidelity}')"
      ],
      "metadata": {
        "id": "R5h5Dmqeyd2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(2,2), dpi=200)\n",
        "plt.scatter(VTC[0,:], predicted_VTC[0,:], s=0.1)\n",
        "plt.xlabel('VTC')\n",
        "plt.ylabel('predicted VTC')\n",
        "plt.axis('equal')"
      ],
      "metadata": {
        "id": "4_ySdi8P1nlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plotting MNIST data"
      ],
      "metadata": {
        "id": "4LRsn_5AyeRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model, test_loader are defined as per previous instructions\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "\n",
        "# Fetch a batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show original images\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.suptitle('Original Images')\n",
        "imshow(torchvision.utils.make_grid(images[:5]))\n",
        "\n",
        "# Reconstruct images through the network\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    images_flat = images.view(images.size(0), -1)\n",
        "    reconstructed, _ = model(images_flat)\n",
        "    # Reshape the images to match the original dimensions\n",
        "    reconstructed_images = reconstructed.view(images.size())\n",
        "\n",
        "# Show reconstructed images\n",
        "plt.figure(figsize=(10, 2))\n",
        "plt.suptitle('Reconstructed Images')\n",
        "imshow(torchvision.utils.make_grid(reconstructed_images[:5]))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8kNpr3qwtZC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}